{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "task1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This cell imports necessary libraries, initializes the BigQuery client,\n",
        "# and sets up global variables for the analysis.\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display, Image, Video\n",
        "from google.cloud import storage\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "client = bigquery.Client(location=\"us-central1\")\n",
        "\n",
        "# IMPORTANT: Verify this PROJECT_ID matches your lab's project ID.\n",
        "PROJECT_ID = '' # <-- YOUR GCP PROJECT ID\n",
        "DATASET_ID = 'cymbal'\n",
        "REGION = 'us-central1'\n",
        "CONNECTION_ID_FOR_EXTERNAL_TABLE = f'{REGION}.gemini_conn'\n",
        "GEMINI_MODEL_NAME = f'{PROJECT_ID}.{DATASET_ID}.gemini_flash_model'\n",
        "GCS_BUCKET_URI = f'gs://{PROJECT_ID}-bucket'\n",
        "CSV_GCS_URI = f'{GCS_BUCKET_URI}/review/customer_reviews.csv'\n",
        "IMAGES_GCS_URI_PATTERN = f'{GCS_BUCKET_URI}/review/images/*'\n",
        "VIDEOS_GCS_URI_PATTERN = f'{GCS_BUCKET_URI}/review/videos/*'\n",
        "\n",
        "# Create the dataset if it doesn't exist to avoid errors.\n",
        "client.create_dataset(DATASET_ID, exists_ok=True)\n",
        "print(f\"Dataset {DATASET_ID} ensured.\")\n",
        "print(f\"BigQuery Client Initialized. Project ID: {PROJECT_ID}\")\n",
        "\n",
        "def run_bq_query(sql: str, client: bigquery.Client):\n",
        "    \"\"\"A helper function to run BigQuery queries and return results.\"\"\"\n",
        "    try:\n",
        "        query_job = client.query(sql)\n",
        "        print(f\"Job {query_job.job_id} in state {query_job.state}\")\n",
        "        if query_job.statement_type == 'SELECT':\n",
        "            df = query_job.to_dataframe()\n",
        "            print(f\"Query complete. Fetched {len(df)} rows.\")"
      ],
      "metadata": {
        "id": "TxOQcoGwPxXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the definitive fix. We create an EXTERNAL TABLE that points directly\n",
        "# to the CSV file in GCS with an explicitly defined schema. This method completely\n",
        "# bypasses any data loading and schema auto-detection issues.\n",
        "table_id_reviews_external = f\"{PROJECT_ID}.{DATASET_ID}.customer_reviews_external\"\n",
        "sql_create_external_table = f\"\"\"\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{table_id_reviews_external}` (\n",
        "    customer_review_id INT64,\n",
        "    customer_id INT64,\n",
        "    location_id INT64,\n",
        "    review_datetime DATETIME,\n",
        "    review_text STRING,\n",
        "    social_media_source STRING,\n",
        "    social_media_handle STRING\n",
        ")\n",
        "OPTIONS (\n",
        "  format = 'CSV',\n",
        "  uris = ['{CSV_GCS_URI}'],\n",
        "  field_delimiter = ',',\n",
        "  skip_leading_rows = 1,\n",
        "  allow_quoted_newlines = TRUE\n",
        ");\n",
        "\"\"\"\n",
        "print(f\"Creating external table: {table_id_reviews_external}...\")\n",
        "run_bq_query(sql_create_external_table, client)"
      ],
      "metadata": {
        "id": "uV2P-pGaKVHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifies the table creation by displaying its first 5 rows.\n",
        "# Confirm that the output shows the 'customer_review_id' and 'review_text' columns.\n",
        "print(f\"\\nVerifying Table: {table_id_reviews_external} (First 5 rows)\")\n",
        "df_verify_reviews = run_bq_query(f\"SELECT customer_review_id, review_text FROM `{table_id_reviews_external}` LIMIT 5\", client)\n",
        "if df_verify_reviews is not None:\n",
        "    display(df_verify_reviews)"
      ],
      "metadata": {
        "id": "RRFlBM9nP5Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates an object table for review images.\n",
        "table_id_review_images = f\"{PROJECT_ID}.{DATASET_ID}.review_images\"\n",
        "sql_create_image_table = f\"\"\"\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{table_id_review_images}`\n",
        "WITH CONNECTION `{CONNECTION_ID_FOR_EXTERNAL_TABLE}`\n",
        "OPTIONS (object_metadata = 'SIMPLE', uris = ['{IMAGES_GCS_URI_PATTERN}']);\n",
        "\"\"\"\n",
        "print(f\"\\nCreating object table for review images: {table_id_review_images}\")\n",
        "run_bq_query(sql_create_image_table, client)\n",
        "\n",
        "# Creates an object table for review videos.\n",
        "table_id_review_videos = f\"{PROJECT_ID}.{DATASET_ID}.review_videos\"\n",
        "sql_create_video_table = f\"\"\"\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{table_id_review_videos}`\n",
        "WITH CONNECTION `{CONNECTION_ID_FOR_EXTERNAL_TABLE}`\n",
        "OPTIONS (object_metadata = 'SIMPLE', uris = ['{VIDEOS_GCS_URI_PATTERN}']);\n",
        "\"\"\"\n",
        "print(f\"\\nCreating object table for review videos: {table_id_review_videos}\")\n",
        "run_bq_query(sql_create_video_table, client)"
      ],
      "metadata": {
        "id": "zWNJWAqXP8MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This SQL command creates a remote model in BigQuery, linking it to the\n",
        "# Gemini Flash endpoint via the connection we set up earlier.\n",
        "sql_create_gemini_model = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{GEMINI_MODEL_NAME}`\n",
        "REMOTE WITH CONNECTION `{CONNECTION_ID_FOR_EXTERNAL_TABLE}`\n",
        "OPTIONS (endpoint = 'gemini-2.0-flash');\n",
        "\"\"\"\n",
        "print(f\"Creating Gemini model: {GEMINI_MODEL_NAME}...\")\n",
        "run_bq_query(sql_create_gemini_model, client)"
      ],
      "metadata": {
        "id": "wnndlvNZP9NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that the source table is guaranteed to have the correct schema,\n",
        "# we can use this simple and efficient 'pass-through' pattern. The model will\n",
        "# process each review and pass through the 'customer_review_id' for easy joining later.\n",
        "\n",
        "# Analyze text for keywords\n",
        "table_id_reviews_keywords = f\"{PROJECT_ID}.{DATASET_ID}.customer_reviews_keywords\"\n",
        "sql_analyze_keywords = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{table_id_reviews_keywords}` AS\n",
        "SELECT\n",
        "  customer_review_id,\n",
        "  ml_generate_text_llm_result AS keywords_json_string\n",
        "FROM ML.GENERATE_TEXT(\n",
        "    MODEL `{GEMINI_MODEL_NAME}`,\n",
        "    (\n",
        "      SELECT\n",
        "        customer_review_id,\n",
        "        CONCAT('Extract keywords from the following customer review. Return as a JSON string array like {{\"keywords\": [\"keyword1\"]}}. Review: ', review_text) AS prompt\n",
        "      FROM\n",
        "        `{table_id_reviews_external}`\n",
        "    ),\n",
        "    STRUCT(0.2 AS temperature, TRUE AS flatten_json_output)\n",
        "  );\n",
        "\"\"\"\n",
        "print(\"Starting customer review keyword analysis...\")\n",
        "run_bq_query(sql_analyze_keywords, client)\n",
        "\n",
        "\n",
        "# Analyze text for sentiment\n",
        "table_id_reviews_analysis = f\"{PROJECT_ID}.{DATASET_ID}.customer_reviews_analysis\"\n",
        "sql_analyze_sentiment = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{table_id_reviews_analysis}` AS\n",
        "SELECT\n",
        "  customer_review_id,\n",
        "  ml_generate_text_llm_result AS sentiment_json_string\n",
        "FROM ML.GENERATE_TEXT(\n",
        "    MODEL `{GEMINI_MODEL_NAME}`,\n",
        "    (\n",
        "      SELECT\n",
        "        customer_review_id,\n",
        "        CONCAT('Classify the sentiment of the following review as \"positive\", \"negative\", or \"neutral\". Return as a JSON string like {{\"sentiment\": \"positive\"}}. Review: ', review_text) AS prompt\n",
        "      FROM\n",
        "        `{table_id_reviews_external}`\n",
        "    ),\n",
        "    STRUCT(0.2 AS temperature, TRUE AS flatten_json_output)\n",
        "  );\n",
        "\"\"\"\n",
        "print(\"\\nStarting customer review sentiment analysis...\")\n",
        "run_bq_query(sql_analyze_sentiment, client)"
      ],
      "metadata": {
        "id": "wvEpKEaFP_qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifies the keywords analysis table. Expect to see a review ID and a JSON string.\n",
        "print(f\"\\n--- Verifying Table: {table_id_reviews_keywords} (First 5 rows) ---\")\n",
        "df_verify_keywords = run_bq_query(f\"SELECT * FROM `{table_id_reviews_keywords}` LIMIT 5\", client)\n",
        "if df_verify_keywords is not None:\n",
        "    display(df_verify_keywords)\n",
        "\n",
        "# Verifies the sentiment analysis table.\n",
        "print(f\"\\n--- Verifying Table: {table_id_reviews_analysis} (First 5 rows) ---\")\n",
        "df_verify_sentiment = run_bq_query(f\"SELECT * FROM `{table_id_reviews_analysis}` LIMIT 5\", client)\n",
        "if df_verify_sentiment is not None:\n",
        "    display(df_verify_sentiment)"
      ],
      "metadata": {
        "id": "j1eaWLWbQAOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invokes Gemini to analyze the content of each image in the object table.\n",
        "table_id_image_results = f\"{PROJECT_ID}.{DATASET_ID}.review_images_results\"\n",
        "sql_analyze_images = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{table_id_image_results}` AS\n",
        "SELECT uri, ml_generate_text_llm_result AS image_analysis_json\n",
        "FROM ML.GENERATE_TEXT( MODEL `{GEMINI_MODEL_NAME}`, TABLE `{table_id_review_images}`,\n",
        "    STRUCT('For each image, summarize it and extract relevant keywords. Answer in JSON with keys \"summary\" and \"keywords\".' AS prompt, TRUE AS flatten_json_output)\n",
        ");\n",
        "\"\"\"\n",
        "print(\"\\nStarting image analysis...\")\n",
        "run_bq_query(sql_analyze_images, client)\n",
        "\n",
        "# Invokes Gemini to analyze the content of each video in the object table.\n",
        "table_id_video_results = f\"{PROJECT_ID}.{DATASET_ID}.review_videos_results\"\n",
        "sql_analyze_videos = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{table_id_video_results}` AS\n",
        "SELECT uri, ml_generate_text_llm_result AS video_analysis_json\n",
        "FROM ML.GENERATE_TEXT( MODEL `{GEMINI_MODEL_NAME}`, TABLE `{table_id_review_videos}`,\n",
        "    STRUCT('For each video, summarize it and extract keywords. Answer in JSON with keys \"summary\" and \"keywords\".' AS prompt, TRUE AS flatten_json_output)\n",
        ");\n",
        "\"\"\"\n",
        "print(\"\\nStarting video analysis...\")\n",
        "run_bq_query(sql_analyze_videos, client)"
      ],
      "metadata": {
        "id": "oyqwNiHWQCTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell fetches and displays media files for direct comparison with the analysis results.\n",
        "storage_client = storage.Client()\n",
        "\n",
        "print(f\"\\n--- Displaying Individual Image Samples & Analysis ---\")\n",
        "df_img_samples = run_bq_query(f\"SELECT uri, image_analysis_json FROM `{table_id_image_results}` LIMIT 2\", client)\n",
        "if df_img_samples is not None:\n",
        "    for _, row in df_img_samples.iterrows():\n",
        "        print(\"-\" * 30)\n",
        "        print(f\"Analysis for: {row['uri']}\")\n",
        "        display(HTML(f\"<pre style='white-space: pre-wrap;'>{row['image_analysis_json']}</pre>\"))\n",
        "        try:\n",
        "            bucket_name, blob_name = row['uri'].replace(\"gs://\", \"\").split(\"/\", 1)\n",
        "            display(Image(data=storage_client.bucket(bucket_name).blob(blob_name).download_as_bytes(), width=300))\n",
        "        except Exception as e:\n",
        "            print(f\"--> Could not display image {row['uri']}. Error: {e}\")\n",
        "\n",
        "print(f\"\\n--- Displaying Individual Video Samples & Analysis ---\")\n",
        "df_vid_samples = run_bq_query(f\"SELECT uri, video_analysis_json FROM `{table_id_video_results}` LIMIT 1\", client)\n",
        "if df_vid_samples is not None:\n",
        "    for _, row in df_vid_samples.iterrows():\n",
        "        print(\"-\" * 30)\n",
        "        print(f\"Analysis for: {row['uri']}\")\n",
        "        display(HTML(f\"<pre style='white-space: pre-wrap;'>{row['video_analysis_json']}</pre>\"))\n",
        "        try:\n",
        "            display(Video(row['uri'], embed=True, width=400))\n",
        "        except Exception as e:\n",
        "            print(f\"--> Could not display video {row['uri']}. Error: {e}\")"
      ],
      "metadata": {
        "id": "28vMBGJ3QEPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The regular expression in REGEXP_EXTRACT is corrected to have only one capturing group `(\\\\d+)`.\n",
        "# This allows us to join the image/video analysis back to the original review by extracting the review ID from the filename.\n",
        "table_id_multimodal_reviews = f\"{PROJECT_ID}.{DATASET_ID}.multimodal_customer_reviews\"\n",
        "sql_create_multimodal_table = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{table_id_multimodal_reviews}` AS\n",
        "WITH\n",
        "  image_results_parsed AS (\n",
        "    SELECT SAFE_CAST(REGEXP_EXTRACT(uri, r'Review.*\\\\((\\\\d+)\\\\)') AS INT64) AS customer_review_id, uri AS image_uri, image_analysis_json\n",
        "    FROM `{table_id_image_results}`\n",
        "  ),\n",
        "  video_results_parsed AS (\n",
        "    SELECT SAFE_CAST(REGEXP_EXTRACT(uri, r'Video.*\\\\((\\\\d+)\\\\)') AS INT64) AS customer_review_id, uri AS video_uri, video_analysis_json\n",
        "    FROM `{table_id_video_results}`\n",
        "  )\n",
        "SELECT\n",
        "    cr.*, -- Select all columns from the correctly-defined source table\n",
        "    s.sentiment_json_string,\n",
        "    k.keywords_json_string,\n",
        "    irp.image_uri,\n",
        "    irp.image_analysis_json,\n",
        "    vrp.video_uri,\n",
        "    vrp.video_analysis_json\n",
        "FROM `{table_id_reviews_external}` AS cr\n",
        "LEFT JOIN `{table_id_reviews_analysis}` AS s ON cr.customer_review_id = s.customer_review_id\n",
        "LEFT JOIN `{table_id_reviews_keywords}` AS k ON cr.customer_review_id = k.customer_review_id\n",
        "LEFT JOIN image_results_parsed AS irp ON cr.customer_review_id = irp.customer_review_id\n",
        "LEFT JOIN video_results_parsed AS vrp ON cr.customer_review_id = vrp.customer_review_id;\n",
        "\"\"\"\n",
        "print(\"Creating unified multimodal analysis table...\")\n",
        "run_bq_query(sql_create_multimodal_table, client)"
      ],
      "metadata": {
        "id": "yVuR5nvFQFzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifies the final unified table by selecting rows where the customer_review_id is between 1 and 30.\n",
        "print(f\"\\nVerifying Unified Multimodal Table: {table_id_multimodal_reviews} (Review IDs 1-30)\")\n",
        "df_sample_multimodal = run_bq_query(f\"\"\"\n",
        "    SELECT\n",
        "        customer_review_id,\n",
        "        review_text,\n",
        "        sentiment_json_string,\n",
        "        image_uri,\n",
        "        video_uri\n",
        "    FROM `{table_id_multimodal_reviews}`\n",
        "    WHERE customer_review_id BETWEEN 1 AND 30\n",
        "    ORDER BY customer_review_id\n",
        "\"\"\", client)\n",
        "\n",
        "if df_sample_multimodal is not None:\n",
        "    display(df_sample_multimodal)"
      ],
      "metadata": {
        "id": "RmkLRtmRQHSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize Sentiment Distribution with GenAI\n",
        "#For this step, you will use the notebook's built-in generative AI assistant to create a plot for you.\n",
        "\n",
        "#Click the + Code button to add a new code cell.\n",
        "#Inside the new cell, click the Generate button.\n",
        "#In the prompt box, type the following as a comment: # plot a bar chart for the distribution of text_sentiment in the multimodal_customer_reviews table\n",
        "#Accept the suggested code, then run the cell to display the chart. This provides a quick overview of the overall sentiment balance."
      ],
      "metadata": {
        "id": "5Xw9zKyVQJcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell queries sentiment counts by date and uses matplotlib to plot the trends.\n",
        "# We parse the sentiment from the JSON string for this visualization.\n",
        "print(f\"\\nGenerating Review Sentiment Trends Plot\")\n",
        "sql_sentiment_trends = f\"\"\"\n",
        "SELECT\n",
        "    DATE(review_datetime) AS review_date,\n",
        "    JSON_EXTRACT_SCALAR(sentiment_json_string, '$.sentiment') as text_sentiment,\n",
        "    COUNT(*) AS sentiment_count\n",
        "FROM `{table_id_multimodal_reviews}`\n",
        "WHERE sentiment_json_string IS NOT NULL AND review_datetime IS NOT NULL\n",
        "GROUP BY 1, 2 ORDER BY 1, 2;\n",
        "\"\"\"\n",
        "df_sentiment_trends = run_bq_query(sql_sentiment_trends, client)\n",
        "if df_sentiment_trends is not None and not df_sentiment_trends.empty:\n",
        "    df_pivot = df_sentiment_trends.pivot_table(index='review_date', columns='text_sentiment', values='sentiment_count', fill_value=0)\n",
        "    df_pivot.plot(kind='line', figsize=(15, 7), style='-o',\n",
        "                  title='Customer Review Sentiment Trends Over Time',\n",
        "                  xlabel='Date of Review', ylabel='Number of Reviews')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XHKDbRxgQLyp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}